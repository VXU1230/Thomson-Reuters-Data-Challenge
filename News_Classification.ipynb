{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.data import load\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>TOPIC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RITE AID CORP &lt;RAD&gt; SETS DIVIDEND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEL E. WEBB INVESTMENT &lt;DWPA&gt; 4TH QTR NET</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENERAL HOST CORP &lt;GH&gt; SETS QUARTERLY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROFESSOR LIFTS BANC TEXAS &lt;BTX&gt; PREFERRED STAKE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WINCHELL'S DONUT &lt;WDH&gt; SETS INITIAL QUARTERLY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  TOPIC\n",
       "ID                                                         \n",
       "0                  RITE AID CORP <RAD> SETS DIVIDEND      0\n",
       "1          DEL E. WEBB INVESTMENT <DWPA> 4TH QTR NET      0\n",
       "2              GENERAL HOST CORP <GH> SETS QUARTERLY      0\n",
       "3   PROFESSOR LIFTS BANC TEXAS <BTX> PREFERRED STAKE      1\n",
       "4      WINCHELL'S DONUT <WDH> SETS INITIAL QUARTERLY      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train1.csv\",index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOPIC</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TITLE\n",
       "TOPIC       \n",
       "0       3107\n",
       "1       2406\n",
       "2       2404"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if it's unbalance\n",
    "df.groupby(\"TOPIC\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>TOPIC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TITLE, TOPIC]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing value\n",
    "df[df[\"TITLE\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words(\"english\"))\n",
    "punc = set(string.punctuation)\n",
    "punc.update([\"--\",\"jan\",\"january\",\"feb\",\"february\",\"mar\",\"march\",\"apr\",\"april\",\"may\",\"jun\",\"june\",\"jul\",\"july\",\n",
    "             \"aug\",\"august\",\"sept\",\"september\",\"oct\",\"october\",\"nov\",\"november\",\"dec\",\"december\"])\n",
    "lemma = WordNetLemmatizer()\n",
    "treetags = load('help/tagsets/upenn_tagset.pickle').keys()\n",
    "\n",
    "posdic = dict(map(lambda x: (x, wordnet.ADJ) if x.startswith('J')\n",
    " else((x, wordnet.ADV) if x.startswith('R')\n",
    "    else((x, wordnet.VERB) if x.startswith('V')\n",
    "         else(x, wordnet.NOUN))), treetags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sent):\n",
    "    sent = sent.lower().replace(\"<\",\" \").replace(\">\", \" \").split()\n",
    "    sent = [lemma.lemmatize(word, posdic[pos]) for (word,pos) in pos_tag(sent) \n",
    "            if (word.isalpha()) & (word not in stop) & (word not in punc) ]  \n",
    "    return \" \".join(word for word in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"FEATURE\"] = [clean(row) for row in df[\"TITLE\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF & Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer  = CountVectorizer(min_df=2,ngram_range=(1,3))\n",
    "n_gram = vectorizer.fit_transform(df[\"FEATURE\"])\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7917x10091 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 63471 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_gram = TfidfTransformer(norm = \"l1\").fit_transform(n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7917x10091 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 63471 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(2,7):\n",
    "    lda = LDA(n_components=i,learning_method='batch', max_iter=100,random_state=rand_state).fit(n_gram)\n",
    "    perplexity = lda.perplexity(n_gram)\n",
    "    score = lda.score(n_gram)\n",
    "    print('\\nPerplexity of %d topics: ' %i, perplexity)\n",
    "    print('score: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(n_components=3,learning_method='batch',random_state=rand_state).fit(n_gram)\n",
    "lda_data = lda.transform(n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1784386 , 0.33701549, 2.32817181, ..., 0.38196381, 0.41092557,\n",
       "        2.31784797],\n",
       "       [0.33486781, 2.32906653, 0.33368499, ..., 3.28391195, 2.15963721,\n",
       "        0.3484502 ],\n",
       "       [0.48669359, 0.33391798, 0.33814319, ..., 0.33412424, 0.42943723,\n",
       "        0.33370182]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = lda.components_\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qtr,net,inc,qtr net,corp,loss,year,co,qtr loss,dividend\n",
      "say,oil,bank,raise,price,unit,rate,pct,buy,set\n",
      "pct,market,money,mln,stock,rise,see,japan,set,buy\n"
     ]
    }
   ],
   "source": [
    "num_words  = 10\n",
    "for _, topic in enumerate(topics):\n",
    "    print (\",\".join([feature_names[i] for i in topic.argsort()[:-num_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'C': [0.1,1,10,50],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': [0.01, 0.1, 1]     \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator = svm.SVC(), cv=5, n_jobs=-1, param_grid=param_grid, scoring = \"accuracy\",verbose = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(lda_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(grid):\n",
    "    print(\"best score: \", grid.best_score_)\n",
    "    print(\"best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[\"FEATURE\"]\n",
    "y_train = df[\"TOPIC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('vectorizer', CountVectorizer()), \n",
    "              ('tfidf',TfidfTransformer()),\n",
    "#                ('lda', LDA(learning_method='batch',max_iter=10,random_state=rand_state)), \n",
    "               ('rf', RandomForestClassifier())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(memory=None,steps = estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'vectorizer__ngram_range': [(1,4),(1,3)],\n",
    "        'vectorizer__min_df': [3, 4],\n",
    "#         'lda__n_components': [5,7,9],\n",
    "        'tfidf__norm': ['l1','l2'],\n",
    "        'tfidf__use_idf': ['True','False'],\n",
    "        'rf__n_estimators': [1000,2000,2500],\n",
    "        'rf__max_features': [\"sqrt\",\"log2\"],\n",
    "        'rf__max_depth':  [50,70],\n",
    "        'rf__min_samples_split': [20,30],\n",
    "        'rf__min_samples_leaf': [2, 3],\n",
    "        'rf__bootstrap': [True]\n",
    "        \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, scoring = \"accuracy\",verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.8505747126436781\n",
      "best parameters:  {'rf__n_estimators': 2000, 'tfidf__norm': 'l2', 'rf__bootstrap': True, 'vectorizer__min_df': 3, 'vectorizer__ngram_range': (1, 3), 'rf__min_samples_leaf': 2, 'rf__max_features': 'log2', 'rf__max_depth': 50, 'rf__min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "print_results(grid_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best score:  0.8505747126436781\n",
    "best parameters:  {'rf__n_estimators': 2000, 'tfidf__norm': 'l2', 'rf__bootstrap': True, 'vectorizer__min_df': 3, \n",
    "        'vectorizer__ngram_range': (1, 3), 'rf__min_samples_leaf': 2, 'rf__max_features': 'log2', \n",
    "                   'rf__max_depth': 50, 'rf__min_samples_split': 20}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('vectorizer', CountVectorizer()), \n",
    "              ('tfidf',TfidfTransformer()),\n",
    "#                ('lda', LDA(learning_method='batch',random_state=rand_state)), \n",
    "               ('logit', LogisticRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(memory=None,steps = estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'vectorizer__ngram_range': [(1,5),(1,4),(1,3)],\n",
    "        'vectorizer__min_df': [3,4],\n",
    "        'tfidf__norm': ['l1','l2'],\n",
    "        'tfidf__use_idf': ['True','False'],\n",
    "#         'lda__n_components': [8,10,12],\n",
    "        'logit__penalty': ['l1', 'l2'], \n",
    "        'logit__C': [0.1,1,10]      \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logit = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, scoring = \"accuracy\", verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.8880889225716811\n",
      "best parameters:  {'vectorizer__ngram_range': (1, 3), 'vectorizer__min_df': 3, 'tfidf__norm': 'l2', 'logit__penalty': 'l2', 'logit__C': 10}\n"
     ]
    }
   ],
   "source": [
    "print_results(grid_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM-SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('vectorizer', CountVectorizer()), \n",
    "              ('tfidf',TfidfTransformer()),\n",
    "#                ('lda', LDA(learning_method='batch',random_state=rand_state)), \n",
    "               ('svc', svm.SVC())]\n",
    "\n",
    "pipe = Pipeline(memory=None,steps = estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'vectorizer__ngram_range': [(1,2),(1,3),(1,4)],\n",
    "        'vectorizer__min_df': [2,3],\n",
    "        'tfidf__norm': ['l1','l2'],\n",
    "        'tfidf__use_idf': ['True','False'],\n",
    "#         'lda__n_components': [4,7,10],\n",
    "        'svc__C': [0.1,1,10],\n",
    "        'svc__kernel': ['rbf'],\n",
    "        'svc__degree': [2,4,6],\n",
    "        'svc__gamma': [0.5, 1]\n",
    "    \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svc = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, scoring = \"accuracy\",verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.8947833775419982\n",
      "best parameters:  {'svc__C': 1, 'svc__gamma': 1, 'svc__kernel': 'rbf', 'tfidf__norm': 'l2', 'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 3, 'svc__degree': 2, 'tfidf__use_idf': 'True'}\n"
     ]
    }
   ],
   "source": [
    "print_results(grid_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('vectorizer', CountVectorizer()), \n",
    "              ('tfidf',TfidfTransformer()),\n",
    "#                ('lda', LDA(learning_method='batch',random_state=rand_state)), \n",
    "               ('sgd', SGDClassifier())]\n",
    "\n",
    "pipe = Pipeline(memory=None,steps = estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'vectorizer__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "        'vectorizer__min_df': [3,4],\n",
    "        'tfidf__norm': ['l1','l2'],\n",
    "        'sgd__loss': ['hinge', 'log'],\n",
    "        'sgd__penalty': ['l1','l2','elasticnet'],\n",
    "        'sgd__alpha': [0.0001, 0.001, 0.01, 0.1]\n",
    "    \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sgd = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, scoring = \"accuracy\",verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.8890994063407857\n",
      "best parameters:  {'tfidf__norm': 'l2', 'sgd__alpha': 0.0001, 'vectorizer__min_df': 3, 'vectorizer__ngram_range': (1, 3), 'sgd__loss': 'hinge', 'sgd__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print_results(grid_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('vectorizer', CountVectorizer()), \n",
    "              ('tfidf',TfidfTransformer()),\n",
    "#                ('lda', LDA(learning_method='batch',random_state=rand_state)), \n",
    "               ('knn', KNeighborsClassifier())]\n",
    "\n",
    "pipe = Pipeline(memory=None,steps = estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'vectorizer__ngram_range': [(1,2),(1,3)],\n",
    "        'vectorizer__min_df': [2,3],\n",
    "        'tfidf__norm': ['l1','l2'],\n",
    "        'knn__n_neighbors': [10,25,40],\n",
    "        'knn__weights': ['uniform','distance'],\n",
    "        'knn__algorithm':['brute'],\n",
    "#         'knn__leaf_size':[10,30,50],\n",
    "        'knn__p':[1,2]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, scoring = \"accuracy\",verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.8556271314892004\n",
      "best parameters:  {'tfidf__norm': 'l2', 'knn__weights': 'distance', 'knn__n_neighbors': 25, 'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 3, 'knn__algorithm': 'ball_tree'}\n"
     ]
    }
   ],
   "source": [
    "print_results(grid_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('vectorizer', CountVectorizer()), \n",
    "              ('tfidf',TfidfTransformer()),\n",
    "#                ('lda', LDA(learning_method='batch',random_state=rand_state)), \n",
    "               ('mnb', MultinomialNB())]\n",
    "\n",
    "pipe = Pipeline(memory=None,steps = estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'vectorizer__ngram_range': [(1,2),(1,3),(1,4)],\n",
    "        'vectorizer__min_df': [1,2,3],\n",
    "        'tfidf__norm': ['l1','l2'],\n",
    "        'tfidf__use_idf': ['True','False'],\n",
    "#         'lda__n_components': [4,7,10],\n",
    "        'mnb__alpha': [0.1,0.5,1,10],\n",
    "        'mnb__fit_prior': [True, False]\n",
    "    \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_mnb = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, scoring = \"accuracy\", verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.8769736011115321\n",
      "best parameters:  {'vectorizer__ngram_range': (1, 4), 'tfidf__norm': 'l2', 'mnb__alpha': 0.5, 'mnb__fit_prior': False, 'vectorizer__min_df': 1, 'tfidf__use_idf': 'True'}\n"
     ]
    }
   ],
   "source": [
    "print_results(grid_mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('vectorizer', CountVectorizer()), \n",
    "              ('tfidf',TfidfTransformer()),\n",
    "#                ('lda', LDA(learning_method='batch',random_state=rand_state)), \n",
    "               ('xgb', XGBClassifier(n_jobs=22, objective='multi:softmax', eval_metric = 'merror'))]\n",
    "pipe = Pipeline(memory=None, steps = estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "#         'vectorizer__ngram_range': [(1,2),(1,3)],\n",
    "#         'vectorizer__min_df': [2, 3, 4],\n",
    "#         'tfidf__norm': ['l1','l2'],\n",
    "#         'tfidf__use_idf': ['True','False'],\n",
    "        'xgb__max_depth': [8,9,10],\n",
    "        'xgb__learning_rate': [0.1],\n",
    "        'xgb__n_estimators':[300,350,400],\n",
    "        'xgb__gamma': [0.1],\n",
    "        'xgb__subsample': [0.5,0.6]\n",
    "    \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgb= GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, scoring = \"accuracy\", verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.8676266262473159\n",
      "best parameters:  {'xgb__booster': 'gbtree', 'xgb__gamma': 0.1, 'xgb__n_estimators': 300, 'xgb__max_depth': 8, 'xgb__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print_results(grid_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>TOPIC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDONESIAN COFFEE PRODUCTION MAY FALL THIS YEAR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTERNATIONAL BUSINESS MACHINES CORP &lt;IBM&gt; NET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WESTERN TELE-COMMUNICATIONS &lt;WTLCA&gt; 4TH QTR NET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NACCO INDUSTRIES &lt;NC&gt; TO REPORT 2ND QTR GAIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WALKER TELECOMMUNICATIONS CORP &lt;WTEL&gt; 4TH QTR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TITLE  TOPIC\n",
       "ID                                                        \n",
       "0   INDONESIAN COFFEE PRODUCTION MAY FALL THIS YEAR    NaN\n",
       "1    INTERNATIONAL BUSINESS MACHINES CORP <IBM> NET    NaN\n",
       "2   WESTERN TELE-COMMUNICATIONS <WTLCA> 4TH QTR NET    NaN\n",
       "3      NACCO INDUSTRIES <NC> TO REPORT 2ND QTR GAIN    NaN\n",
       "4     WALKER TELECOMMUNICATIONS CORP <WTEL> 4TH QTR    NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"test1.csv\",index_col = 0)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = [clean(row) for row in df2[\"TITLE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('vectorizer', CountVectorizer(ngram_range=(1,2),min_df=3)), \n",
    "              ('tfidf',TfidfTransformer(use_idf=True, norm='l2')),\n",
    "               ('svc', svm.SVC(C=1, gamma=1, kernel ='rbf',degree=2))]\n",
    "\n",
    "pipe = Pipeline(memory=None,steps = estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "       ...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820639130983958"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipe.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"TOPIC\"] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOPIC</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TITLE\n",
       "TOPIC       \n",
       "0       1203\n",
       "1       1095\n",
       "2       1095"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(\"TOPIC\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
